{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvwQZ0N7u3qz"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8poJPGsu3q1",
        "outputId": "0f8b0c48-4ce9-4ad8-a7ed-3b8cb62ac796"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = 'finalMergedData.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# df = pd.read_csv(\"./finalMergedData.csv\")\n",
        "# Assuming your DataFrame is called df\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh8Lj1Wlu3q2"
      },
      "outputs": [],
      "source": [
        "df.columns\n",
        "columns = ['gameId','ballCarrierId','ballCarrierDisplayName','playDescription','passResult','passLength','penaltyYards','prePenaltyPlayResult','playNullifiedByPenalty',\n",
        "           'homeTeamWinProbabilityAdded','visitorTeamWinProbilityAdded','expectedPointsAdded','foulNFLId1','foulNFLId2','frameId',\n",
        "           'Full Name','teamId','foulName1','foulName2']\n",
        "df = df.drop(columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhE7DZ46u3q3"
      },
      "outputs": [],
      "source": [
        "#this piece of data processing code is snipped from other people's kaggle notebook record.\n",
        "#https://www.kaggle.com/code/mansooralam559/classification-model-for-nfl-big-data-bowl-2024\n",
        "def convert_height_to_meters(height):\n",
        "    # Split the height into feet and inches\n",
        "    feet, inches = map(int, height.split('-'))\n",
        "    # Convert height to inches\n",
        "    total_inches = feet * 12 + inches\n",
        "    # Convert inches to cm (1 inch = 2.54 cm)\n",
        "    height_cm = total_inches * 2.54\n",
        "    # Convert cm to meters\n",
        "    height_m = height_cm / 100\n",
        "    return height_m\n",
        "df['height_x'] = df['height_x'].apply(convert_height_to_meters)\n",
        "\n",
        "def gameClockConverter(clock):\n",
        "    minutes,second = map(int,clock.split(':'))\n",
        "    totalTime = minutes*60 + second\n",
        "    return totalTime\n",
        "df['gameClock'] = df['gameClock'].apply(gameClockConverter)\n",
        "\n",
        "#the open source kaggle notebook also reminds me of calculating the bmi of a player. This could be essential because it gives a more intuitive\n",
        "#and quantitative information about a player's physique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHMUTS_Pu3q4",
        "outputId": "0e3377da-4dfb-4c32-87a1-3c03198c50ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['yardlineSide'] = df['yardlineSide'].fillna('none')\n",
        "df['offenseFormation']=df['offenseFormation'].fillna('none')\n",
        "# deFendersIntheBoxMean = df['defendersInTheBox'].mean()\n",
        "df['defendersInTheBox'] = df['defendersInTheBox'].fillna(df['defendersInTheBox'].mean())\n",
        "df['passProbability'] = df['passProbability'].fillna(df['passProbability'].mean())\n",
        "\n",
        "df.isna().sum()\n",
        "# deFendersIntheBoxMean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "7oOLC3V6u3q4",
        "outputId": "bd300daa-a7d1-4d9e-d127-bd3d4afea3a7"
      },
      "outputs": [],
      "source": [
        "#EDA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "numerical_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Compute the correlation matrix for numerical features\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "7lR124_5u3q5",
        "outputId": "045d8eee-119e-4bd1-a724-57e2a6aa0e71"
      },
      "outputs": [],
      "source": [
        "df['playId'] = df['playId'].astype('category')\n",
        "\n",
        "# Plot barplot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='playId', y='playResult', data=df)\n",
        "plt.title('Play Result by Play ID')\n",
        "plt.xlabel('Play ID')\n",
        "plt.ylabel('Play Result')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "mRjSsMpeu3q6",
        "outputId": "db71e224-bc7b-46df-a079-be76616ff862"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['playResult'], kde=True, stat='density')\n",
        "plt.title('Probability Density Function of playResult')\n",
        "plt.xlabel('playResult')\n",
        "plt.ylabel('Density')\n",
        "plt.show()\n",
        "#we can tell it is normally distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElKT1BAgu3q6",
        "outputId": "15ba89c5-c549-4856-84a2-51b6f448fbf3"
      },
      "outputs": [],
      "source": [
        "#scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Get list of numerical column names\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Remove playResult from numerical_cols\n",
        "numerical_cols.remove('playResult')\n",
        "\n",
        "# Separate numerical and categorical features\n",
        "X_numerical = df[numerical_cols]  # Only include numerical columns\n",
        "X_categorical = df.drop(columns=numerical_cols + ['playResult'])  # Exclude numerical and target columns\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Standardize numerical features (excluding playResult)\n",
        "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
        "\n",
        "# Convert the standardized numerical features back to a DataFrame\n",
        "X_numerical_scaled_df = pd.DataFrame(X_numerical_scaled, columns=X_numerical.columns)\n",
        "\n",
        "# Concatenate the standardized numerical features with the categorical features and playResult column\n",
        "df_standardized = pd.concat([X_numerical_scaled_df, X_categorical, df['playResult']], axis=1)\n",
        "\n",
        "# Now df_standardized contains the entire dataset with numerical features standardized except for playResult\n",
        "numerical_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "byWo-Fcgu3q7",
        "outputId": "2905d032-2c7e-4d1e-93e8-408d2f4b180c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['playResult'], df['overall_rating'])\n",
        "plt.title('Scatter Plot between playResult and overallRating')\n",
        "plt.xlabel('playResult')\n",
        "plt.ylabel('overallRating')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "8CwHtzTvu3q7",
        "outputId": "9e76ac77-2eee-487b-b3dd-d4c159f9b1ed"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['playResult'], df['passProbability'])\n",
        "plt.title('Scatter Plot between playResult and pass probability')\n",
        "plt.xlabel('playResult')\n",
        "plt.ylabel('pass probability')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "IOhWJxeIu3q8",
        "outputId": "29dbdd65-36e4-4eff-dcab-836b466e516f"
      },
      "outputs": [],
      "source": [
        "df_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "GdpBrVlku3q9",
        "outputId": "c9faada4-c392-4f82-d30c-43a28011cf81"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "numeric_df = df_standardized.select_dtypes(include=['number'])\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = numeric_df.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_df.values, i) for i in range(len(numeric_df.columns))]\n",
        "vif_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTXZyGS2u3q9"
      },
      "outputs": [],
      "source": [
        "df_standardized  = df_standardized.drop(columns=['preSnapVisitorTeamWinProbability'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61-ytvvru3q-"
      },
      "outputs": [],
      "source": [
        "# object_columns = df_standardized.select_dtypes(include=['object']).columns\n",
        "# df_standardized[object_columns] = df_standardized[object_columns].astype('category')\n",
        "\n",
        "# df_standardized = pd.get_dummies(df_standardized)\n",
        "\n",
        "# df_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysjLUTCWu3q-",
        "outputId": "5e657db4-018a-4244-9481-e69bb2fdc126"
      },
      "outputs": [],
      "source": [
        "object_columns = df_standardized.select_dtypes(include=['object']).columns\n",
        "df_standardized[object_columns] = df_standardized[object_columns].astype('category')\n",
        "categorical_features = df_standardized.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "# Print the list of categorical feature names\n",
        "print(\"Categorical Features:\", categorical_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_l4ePkQu3q_",
        "outputId": "15b73dab-0932-4c02-ccb0-96f785c446b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df_standardized.drop(columns=['playResult'])  # Features\n",
        "y = df_standardized['playResult']  # Target\n",
        "\n",
        "# First split: Split the data into training (70%) and temporary (30%)\n",
        "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Second split: Split the temporary data into validation (50%) and final training (50%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_val = X_val.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_val = y_val.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n",
        "# print(X_train['playId'].nunique())# this is a lot of different plays\n",
        "X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJZQ7870u3rA",
        "outputId": "019414fb-0bdf-44b4-fe17-8e77ca77fb77"
      },
      "outputs": [],
      "source": [
        "#lightgbm does not seem to work\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',  # Regression task\n",
        "    'metric': 'l2',             # Mean squared error (MSE) as the evaluation metric\n",
        "    'num_leaves': 31,            # Number of leaves in each tree\n",
        "    'learning_rate': 0.05,       # Learning rate\n",
        "    'feature_fraction': 0.2,     # Feature fraction (randomly select a subset of features)\n",
        "    'bagging_fraction': 1.0,     # Bagging fraction (randomly select a subset of data)\n",
        "    'bagging_freq': 5,           # Frequency for bagging\n",
        "    'verbose': 0                 # Verbosity\n",
        "}\n",
        "train_data = lgb.Dataset(X_train, label=y_train,categorical_feature=categorical_features)\n",
        "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "num_round = 100\n",
        "bst = lgb.train(params, train_data, num_round, valid_sets=[val_data])\n",
        "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DcGgXSPu3rA",
        "outputId": "8b29b4da-7250-4cd2-b763-6aec4e244cb6"
      },
      "outputs": [],
      "source": [
        "sklearn.metrics.get_scorer_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6c3ydZku3rB",
        "outputId": "4d9717f2-ff8c-41f4-c726-70b6ddaacc04"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'objective': ['regression'],\n",
        "    'metric': ['l2'],\n",
        "    'num_leaves':[31,50,80],\n",
        "    'min_data_in_leaf': [10,20, 50, 100],  # Adjusting parameter name for clarity\n",
        "    'max_depth': [15, 20,25,30],\n",
        "    'lambda_l2': [0.0, 0.01, 0.03,0.06],\n",
        "    'learning_rate': [0.05, 0.03, 0.04],\n",
        "    'feature_fraction': [0.5,0.6,0.7],\n",
        "    'bagging_fraction': [1.0],\n",
        "    'bagging_freq': [10],\n",
        "    'verbose': [0],\n",
        "    'n_jobs': [-1]  # Use all CPU cores for LightGBM\n",
        "}\n",
        "\n",
        "# Create the LightGBM regressor model\n",
        "model = lgb.LGBMRegressor(n_jobs=-1)  # This will use all cores for each individual LightGBM training process\n",
        "\n",
        "# Perform hyperparameter tuning with GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = best_model.predict(X_val)\n",
        "\n",
        "# Evaluate the model using Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N22WwOHBu3rC",
        "outputId": "a06c9928-02e7-4136-96cc-bf9ae2f6cf89"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error (MSE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute error:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ytqI-Xu3rC",
        "outputId": "217a69cf-476e-4551-b1d6-a6f2d3dcf5ca"
      },
      "outputs": [],
      "source": [
        "feature_range = y_test.max() - y_test.min()\n",
        "\n",
        "print(\"Range of the feature:\", feature_range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAxww6KYu3rD",
        "outputId": "af1577f7-e3b7-42b0-e144-f704d2e8960a"
      },
      "outputs": [],
      "source": [
        "\n",
        "samples = np.random.normal(loc=df_standardized['playResult'].mean(), scale=np.sqrt(df_standardized['playResult'].var()), size=y_test.shape[0])\n",
        "mae = mean_absolute_error(samples,y_test)\n",
        "mae"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
